# **OllamaRun**

The OllamaRun Kaggle notebook enables users who do not have the compute resources to run open-source LLMs on their machines to access the GPUs and storage necessary to run these models. You can check out the [Ollama library](https://ollama.com/library) for the list of open-source models that can be pulled and run locally.
